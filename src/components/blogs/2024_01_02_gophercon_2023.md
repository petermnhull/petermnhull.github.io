## GopherCon UK 2023

02.01.2024

Last year I attended GopherCon UK, the annual UK-based conference focused on the Go programming language.

The conference consisted of talks and workshops over 2 days, covering everything from the latest features presented by the Go team at Google, deep-dives into Go internals, and success stories throughout the Go start-up community.

So, to kick off 2024, this is a short review of the most interesting parts of last year's event and what we can expect going forward.

### The State of Go in 2023

The first keynote was given by one of the Product Managers at Google itself for Go!

They kicked off with a short history of the language; the introduction of modules in 2018 got a special shoutout, and the release of 1.15 in late 2020 was called the turning point when Go turned into an established language. This certainly lines up with when I first started hearing about Go being used in a variety of production environments, and I'm personally glad I wasn't too heavily involved with Go before we needed to worry about the `GOPATH` and the lack of modules.

Following this we got the biggest news of the conference: that there will *never* be a "Go 2". This might not seem like a surprise given that we know how dedicated the team are to backwards compatibility, but it was surprising to hear a definitive answer to the question on when a major version change would happen. This is great news for those of us who had to work through the painful Python 2 to Python 3 migration.

### Standard Logging

Next, Jonathan Amsterdam, a Software Engineer at Google who works on Go, gave a talk on the Standard Logging library introduced in Go 1.21.

We not only learned about a fantastic new tool to use which provides inter-operability with existing logging frameworks, but we gained incredible insight into how Google actually develop Go and what their priorities are. To put it concretely, Jonathan described three guiding principles: data-driven development, working early and often with the community, and designing Go to be "light".

The data guiding the development of the standard logger was primarily around performance, and understanding the existing use cases so that the library would be as fast as needed, but crucially stopping at that point before over-optimising. For example, the Go team analysed the number of keys used in clients of existing logging packages such as Logrus and Zap. Eventually, they settled on designing the library to be as fast as Zap but not as fast as Zerolog, as optimising further in a manner similar to Zap would have introduced the risk of use-after-free bugs present in the Zerolog API. This was weighed up against the fact that there are a tiny amount of use cases where one would actually benefit from the performance boost. 

The most technical part of the talk came when Jonathan described how to achieve high performance by avoiding allocations. This is important in Go, as using the heap is slow and creates garbage which needs to be detected by escape analysis and removed with the garbage collector. One area where this influenced the design was in using a concrete type for the Logger, even though its associated *Handler* is an interface, to avoid indirect calls.

The implementation then needed to be checked with good performance benchmarks, which the team achieved by using [x/perf/cmd/benchstat](https://pkg.go.dev/golang.org/x/perf@v0.0.0-20231127181059-b53752263861/cmd/benchstat). They recommended that when writing performance benchmarks it's critical to always write the calls how you would do so in your application code, otherwise the optimisation in the compiler can obscure the results.

I would highly recommend reading the [standard logging Handler guide](https://pkg.go.dev/golang.org/x/example/slog-handler-guide#section-readme) written by the speaker for more information on the design and how to use it in your services.

### Modifying the Go Runtime

On the second day, Dominic Black from [Encore](https://encore.dev/), a development platform for automatically provisioning infrastructure and observability in the cloud, presented a talk on how to modify the Go runtime.

Why would you want to do that? Well, Encore do it so they can automatically inject tracing directly into your Go application, meaning that you can give your app to them and they'll give you back a Jaeger dashboard where you can see low-level network calls deep in the Go stack... ðŸ¤¯

Dominic gave an example of how you can identify when go-routines start and end by adding trace identifiers, which lets you trace actions such as DNS resolution. This sounds simple enough, but requires heavy use of the [unsafe](https://pkg.go.dev/unsafe) package, using the `linkname` directive to get around circular dependencies, and adding empty `tracing.s` files to trick the Go runtime into thinking there is Assembly code to compile when there isn't.

As you can probably guess, the full details of how exactly they did this are a bit beyond the scope of this blog post, and that's why if I were to recommend one recording to watch from GopherCon it would be [this one](https://www.youtube.com/watch?v=MRZU5J29Rys), especially as the talk ends with a demonstration of the resulting tracing in Jaeger UI.

For my role at Arenko, my main take-away was to implement tracing more consistently so that we could get closer to the level of observability that we were shown in this talk. But it's good to know how to mess with the Go runtime if the opportunity ever arises!

### The Go Compiler

Finally, the last talk I went to was a deep-dive into the Go compiler. The main conclusion for me was that the compiler is basically just fancy data transformation - the goal is to take the Go code in your IDE and turn it into machine code that can be ran as an executable. Sure, there are some optimisations that take place, but after listening to this talk I became a lot less scared of digging into the compiler source code myself.

To summarise, there are 10 steps to go from Go code to an executable:

1. The Scanner - Generate tokens by scanning character by character.
2. The Parser - Generate an Abstract Syntax Tree (AST) per file.
3. The Type Checker - Check some types (the speaker did not go into any detail here, and implied it needed it's own talk!).
4. The Intermediary Representation (IR) - Generate one IR per package from the AST, and infer information about types.
5. The IR Passes - Optimise! For example, eliminate dead-code (i.e. code paths that can never be reached) and *de-virtualize* (i.e. replace interfaces with concrete implementations where possible).
6. The Static Single Assignment (SSA) - This is where the code is starting to look like Assembly...
7. The SSA Passes - Use the SSA to further optimise, e.g. by deleting more dead-code that died as a result of previous optimisations. This is also the first step where the hardware is actually relevant.
8. The Machine Code Generation - Create an architecture-specific binary.
9. The Linking - Again, the speaker brushed over this, but essentially this is the stage where we link up with the Go runtime.
10. The Execution!

### Conclusion

There was a lot to learn over the 2 days I spent at GopherCon, including topics I didn't cover here like using distributed tracing for end-to-end testing and building debuggers from scratch. So whether you're a developer just starting out with Go or one keen to dive deeper into the community and the language, I highly recommend looking out for GopherCon 2024 later this year.
